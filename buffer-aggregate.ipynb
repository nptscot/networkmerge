{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "format: gfm\n",
        "---"
      ],
      "id": "2c7a529c"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Prerequisites\n",
        "\n",
        "To run the code in this repo, you need to have a working Python installation with the following packages installed (with pip in this case):\n",
        "\n",
        "\n",
        "```{bash}\n",
        "#| eval: false\n",
        "pip install matplotlib pandas shapely geopandas osmnx networkx scipy folium mapclassify grass\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "# networkmerge\n",
        "\n",
        "A minimal example dataset was created with the ATIP tool.\n",
        "The example dataset can be found in the `data` folder.\n",
        "\n",
        "To read-in the data into Python we used the following:\n"
      ],
      "id": "8e62c4cd"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: 'Import necessary library and all defined functions:calculate_total_length, plot_geodataframe_with_labels, plot_geodataframes, filter_data, create_buffer, get_vector, calculate_angle, split_line_at_angles, calculate_angle, filter_parallel_lines_concat, calculate_distance, plot_buffer_with_lines, merge_directly_connected'\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import math\n",
        "from typing import List, Tuple\n",
        "from shapely.geometry import LineString\n",
        "import geopandas as gpd\n",
        "import osmnx as ox\n",
        "import numpy as np\n",
        "from scipy.spatial.distance import pdist, squareform\n",
        "from shapely.geometry import Point, LineString, Polygon, MultiLineString\n",
        "import networkx as nx\n",
        "from pyproj import CRS\n",
        "import folium\n",
        "import os\n",
        "from numpy.linalg import norm\n",
        "from collections import defaultdict\n",
        "from shapely.ops import unary_union\n",
        "import grass as gs\n",
        "\n",
        "# Calculate total length of linestrings in a GeoDataFrame \n",
        "def calculate_total_length(gdf, crs=\"EPSG:4326\"):\n",
        "    # Copy the GeoDataFrame\n",
        "    gdf_projected = gdf.copy()\n",
        "\n",
        "    # Change the CRS to a UTM zone for more accurate length calculation\n",
        "    gdf_projected = gdf_projected.to_crs(crs)\n",
        "\n",
        "    # Calculate the length of each line\n",
        "    gdf_projected[\"length\"] = gdf_projected.length\n",
        "\n",
        "    # Calculate the total length\n",
        "    total_length = gdf_projected[\"length\"].sum()\n",
        "\n",
        "    return total_length\n",
        "\n",
        "# Plot GeoDataFrame and label each feature with its index\n",
        "def plot_geodataframe_with_labels(gdf, gdf_name):\n",
        "\n",
        "    # Create a new figure\n",
        "    fig, ax = plt.subplots(figsize=(10, 10))\n",
        "\n",
        "    # Plot the GeoDataFrame\n",
        "    gdf.plot(ax=ax)\n",
        "\n",
        "    # Add labels for each line with its index\n",
        "    for x, y, label in zip(gdf.geometry.centroid.x, gdf.geometry.centroid.y, gdf.index):\n",
        "        ax.text(x, y, str(label), fontsize=12)\n",
        "    plt.savefig(f\"pics/{gdf_name}.jpg\")\n",
        "    # Display the plot\n",
        "    plt.show()\n",
        "\n",
        "# Create interactive map from one or more GeoDataFrames  \n",
        "def plot_geodataframes(*args, colors=['red', 'blue', 'green'], line_widths=[3.5, 2.5,1.5], marker_sizes=[10, 10, 10], map_type=\"OpenStreetMap\"):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        *args: One or more (name, GeoDataFrame) tuples \n",
        "        colors: List of colors for lines\n",
        "        line_widths: List of line widths\n",
        "        map_type: Folium map type\n",
        "    Returns:\n",
        "        Folium map object\n",
        "    \"\"\"\n",
        "    # Prepare gdfs and their names\n",
        "    gdfs = [arg[1] for arg in args]\n",
        "    names = [arg[0] for arg in args]\n",
        "\n",
        "    # Initialize the map to the first point of the first geodataframe\n",
        "    start_point = gdfs[0].iloc[0].geometry.centroid.coords[0]\n",
        "    m = folium.Map(location=[start_point[1], start_point[0]], zoom_start=15)\n",
        "\n",
        "    if map_type == \"Esri Satellite\":\n",
        "        esri = folium.TileLayer(\n",
        "            tiles=\"https://server.arcgisonline.com/ArcGIS/rest/services/World_Imagery/MapServer/tile/{z}/{y}/{x}\",\n",
        "            attr=\"Esri\",\n",
        "            name=\"Esri Satellite\",\n",
        "            control=True\n",
        "        )\n",
        "        esri.add_to(m)\n",
        "\n",
        "    # Create feature groups for each geodataframe and add them to the map\n",
        "    for i, gdf in enumerate(gdfs):\n",
        "        fg = folium.FeatureGroup(name=names[i], show=False)\n",
        "        for _, row in gdf.iterrows():\n",
        "            if row.geometry.geom_type == 'Point':\n",
        "                marker = folium.Marker(location=[row.geometry.y, row.geometry.x], \n",
        "                                       icon=folium.Icon(color=colors[i % len(colors)]))\n",
        "                fg.add_child(marker)\n",
        "            elif row.geometry.geom_type == 'LineString':\n",
        "                line = folium.vector_layers.PolyLine(locations=[[p[1], p[0]] for p in list(row.geometry.coords)],\n",
        "                                                      color=colors[i % len(colors)],\n",
        "                                                      weight=line_widths[i % len(line_widths)])\n",
        "                fg.add_child(line)\n",
        "\n",
        "            elif row.geometry.geom_type == 'Polygon':\n",
        "                polygon = folium.vector_layers.Polygon(locations=[[p[1], p[0]] for p in list(row.geometry.exterior.coords)],\n",
        "                                                       color=colors[i % len(colors)],\n",
        "                                                       fill=True)\n",
        "                fg.add_child(polygon)\n",
        "            elif row.geometry.geom_type == 'MultiLineString':\n",
        "                for line_geom in row.geometry.geoms:\n",
        "                    coordinates = [list(p) for p in line_geom.coords]\n",
        "                    line = folium.vector_layers.PolyLine(locations=[[p[1], p[0]] for p in coordinates],\n",
        "                                                        color=colors[i % len(colors)],\n",
        "                                                        weight=line_widths[i % len(line_widths)])\n",
        "                    fg.add_child(line)                \n",
        "        m.add_child(fg)\n",
        "\n",
        "    # Add layer control to the map\n",
        "    folium.LayerControl().add_to(m)\n",
        "\n",
        "    return m\n",
        "\n",
        "# Filter GeoDataFrame based on column conditions  \n",
        "def filter_data(gdf, conditions):\n",
        "    \"\"\"\n",
        "    Filter a GeoDataFrame based on multiple conditions.\n",
        "\n",
        "    \"\"\"\n",
        "    for column, condition in conditions.items():\n",
        "        gdf = gdf[condition(gdf[column])]\n",
        "    return gdf\n",
        "\n",
        "# Buffer input geometries by specified distance\n",
        "def create_buffer(gdf, buffer_size = 0.00002):\n",
        "    gdf_buffered = gdf.copy()\n",
        "    gdf_buffered.geometry = gdf.geometry.buffer(buffer_size)\n",
        "    # gdf_buffered.to_file(\"data/gdf_buffered.geojson\", driver='GeoJSON')\n",
        "    return  gdf_buffered\n",
        "\n",
        "# Get start and end points from (Multi)LineString  \n",
        "def get_vector(line):\n",
        "    if isinstance(line, LineString):\n",
        "        start, end = line.coords[:2]\n",
        "    else:  # for MultiLineStrings, just use the first line\n",
        "        start, end = line.geoms[0].coords[:2]\n",
        "    return [end[0] - start[0], end[1] - start[1]]\n",
        "\n",
        "# Calculate angle between two vectors \n",
        "def calculate_angle(vector1, vector2):\n",
        "    dot_product = vector1[0] * vector2[0] + vector1[1] * vector2[1]\n",
        "    magnitude_product = math.sqrt(vector1[0]**2 + vector1[1]**2) * math.sqrt(vector2[0]**2 + vector2[1]**2)\n",
        "    cos_angle = dot_product / magnitude_product\n",
        "    angle = math.degrees(math.acos(cos_angle))\n",
        "    return angle\n",
        "\n",
        "# Modified function to split a line into segments based on an angle threshold and retain the 'value', 'Quietness', and original index\n",
        "def split_line_at_angles(line, value, quietness, original_index, length, angle_threshold=30, max_length=0.001):\n",
        "    segments = []\n",
        "    if isinstance(line, LineString):\n",
        "        coords = np.array(line.coords)\n",
        "        vectors = np.diff(coords, axis=0)\n",
        "        directions = np.arctan2(vectors[:, 1], vectors[:, 0])\n",
        "        angles = np.diff(directions)\n",
        "        angles = np.abs(np.degrees(angles))\n",
        "        split_indices = np.where(angles > angle_threshold)[0] + 1\n",
        "        last_index = 0\n",
        "        for index in split_indices:\n",
        "            segment_coords = coords[last_index:index + 1]\n",
        "            segment = LineString(segment_coords)\n",
        "            while segment.length > max_length:\n",
        "                split_point = segment.interpolate(max_length)\n",
        "                sub_segment_1 = LineString([segment.coords[0], split_point.coords[0]])\n",
        "                sub_segment_2 = LineString([split_point.coords[0]] + list(segment.coords)[1:])\n",
        "                segments.append((sub_segment_1, value, quietness, original_index, sub_segment_1.length))\n",
        "                segment = sub_segment_2\n",
        "            segments.append((segment, value, quietness, original_index, segment.length))\n",
        "            last_index = index\n",
        "        segment_coords = coords[last_index:]\n",
        "        segment = LineString(segment_coords)\n",
        "        while segment.length > max_length:\n",
        "            split_point = segment.interpolate(max_length)\n",
        "            sub_segment_1 = LineString([segment.coords[0], split_point.coords[0]])\n",
        "            sub_segment_2 = LineString([split_point.coords[0]] + list(segment.coords)[1:])\n",
        "            segments.append((sub_segment_1, value, quietness, original_index, sub_segment_1.length))\n",
        "            segment = sub_segment_2\n",
        "        segments.append((segment, value, quietness, original_index, segment.length))\n",
        "    elif isinstance(line, MultiLineString):\n",
        "        for geom in line.geoms:\n",
        "            segments.extend(split_line_at_angles(geom, value, quietness, original_index, geom.length, angle_threshold, max_length))\n",
        "    else:\n",
        "        raise ValueError(f\"Unexpected geometry type: {type(line)}\")\n",
        "\n",
        "    return segments\n",
        "\n",
        "# Calculate angle between two line segments \n",
        "def calculate_angle(line1, line2):\n",
        "    # Define the vectors\n",
        "    vector1 = np.array(line1[1]) - np.array(line1[0])\n",
        "    vector2 = np.array(line2[1]) - np.array(line2[0])\n",
        "    \n",
        "    # Compute the dot product\n",
        "    dot_product = np.dot(vector1, vector2)\n",
        "    \n",
        "    # Compute the magnitudes of the vectors\n",
        "    magnitude1 = np.sqrt(np.dot(vector1, vector1))\n",
        "    magnitude2 = np.sqrt(np.dot(vector2, vector2))\n",
        "    \n",
        "    # Compute the angle between the vectors in radians\n",
        "    angle_rad = np.arccos(dot_product / (magnitude1 * magnitude2))\n",
        "    \n",
        "    # Convert the angle to degrees\n",
        "    angle_deg = np.degrees(angle_rad)\n",
        "    \n",
        "    return angle_deg\n",
        "\n",
        "# Concat parallel linestrings into single geometry\n",
        "def filter_parallel_lines_concat(gdf, name, angle_tolerance=25):\n",
        "    # Filter the GeoDataFrame by the 'name' column\n",
        "    filtered_gdf = gdf[gdf['name'] == name]\n",
        "\n",
        "    # Create a list to store the parallel lines\n",
        "    parallel_lines = []\n",
        "\n",
        "    # Iterate through each pair of lines\n",
        "    for i in range(len(filtered_gdf)):\n",
        "        for j in range(i+1, len(filtered_gdf)):\n",
        "            # Get the lines\n",
        "            line1 = list(filtered_gdf.iloc[i].geometry.coords)\n",
        "            line2 = list(filtered_gdf.iloc[j].geometry.coords)\n",
        "\n",
        "            # Calculate the angle between the lines\n",
        "            angle = calculate_angle(line1, line2)\n",
        "\n",
        "            # If the angle is close to 0 or 180 degrees, add the lines to the list\n",
        "            if abs(angle) <= angle_tolerance or abs(angle - 180) <= angle_tolerance:\n",
        "                parallel_lines.append(filtered_gdf.iloc[i:i+1])\n",
        "                parallel_lines.append(filtered_gdf.iloc[j:j+1])\n",
        "\n",
        "    # Combine the lines into a new GeoDataFrame using pd.concat\n",
        "    parallel_gdf = pd.concat(parallel_lines).drop_duplicates()\n",
        "\n",
        "    return parallel_gdf\n",
        "\n",
        "# Distance between two points\n",
        "def calculate_distance(point1, point2):\n",
        "    return Point(point1).distance(Point(point2))\n",
        "\n",
        "def onclick(event):\n",
        "    if event.inaxes != ax:\n",
        "        return\n",
        "    click_point = Point(event.xdata, event.ydata)\n",
        "    closest_line_index = None\n",
        "    min_distance = float('inf')\n",
        "    for index, row in gdf.iterrows():\n",
        "        distance = row['geometry'].distance(click_point)\n",
        "        if distance < min_distance:\n",
        "            min_distance = distance\n",
        "            closest_line_index = index\n",
        "    if closest_line_index is not None:\n",
        "        line_attributes = gdf.loc[closest_line_index]\n",
        "        print(f\"Clicked near line with index {closest_line_index}. Attributes: {line_attributes.to_dict()}\")\n",
        "\n",
        "# Plot results of line within or intersect with buffer\n",
        "def plot_buffer_with_lines(gdf_buffered, gdf, buffer_index='all', relation='intersect'):\n",
        "    column_name = 'Line_index_from_gdf_Within' if relation == 'within' else 'Line_index_from_gdf_Intersect'\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(12, 8))\n",
        "    fig.canvas.mpl_connect('button_press_event', onclick)\n",
        "    def plot_single_buffer(buffer_idx, buffered_geom):\n",
        "        indices_related_buffer = buffered_geom[column_name]\n",
        "        gpd.GeoSeries([buffered_geom['geometry']]).plot(ax=ax, edgecolor='blue', facecolor='none')\n",
        "\n",
        "        if indices_related_buffer:\n",
        "            gdf.loc[indices_related_buffer].plot(ax=ax, color='red')\n",
        "            for idx in indices_related_buffer:\n",
        "                line_value = gdf.loc[idx, 'value']\n",
        "                annotation_text = f\"{idx} - {line_value}\"\n",
        "                centroid = gdf.loc[idx, 'geometry'].centroid.coords[0]\n",
        "                plt.text(centroid[0], centroid[1] + 0.00005, annotation_text, fontsize=9, color='red', ha='center')\n",
        "        else:\n",
        "            plt.text(buffered_geom['geometry'].centroid.x, buffered_geom['geometry'].centroid.y - 0.00015, \"No lines \" + relation, fontsize=9, color='blue', ha='center')\n",
        "\n",
        "        plt.text(buffered_geom['geometry'].centroid.x, buffered_geom['geometry'].centroid.y - 0.00035, f\"Buffer Index: {buffer_idx}\", fontsize=9, color='blue', ha='center')\n",
        "\n",
        "    if buffer_index == 'all':\n",
        "        for buffer_idx, buffered_geom in gdf_buffered.iterrows():\n",
        "            plot_single_buffer(buffer_idx, buffered_geom)\n",
        "        plt.title(f'Buffered Geometries (Blue) with {relation.capitalize()} Lines (Red)')\n",
        "    elif isinstance(buffer_index, int):\n",
        "        plot_single_buffer(buffer_index, gdf_buffered.loc[buffer_index])\n",
        "        plt.title(f'Buffered Geometry (Blue) with {relation.capitalize()} Lines (Red) for Buffer Index {buffer_index}')\n",
        "\n",
        "    plt.xlabel('Longitude')\n",
        "    plt.ylabel('Latitude')\n",
        "    plt.show()\n",
        "\n",
        "# Function to merge directly connected line segments within a group\n",
        "def merge_directly_connected(group):\n",
        "    lines = list(group['geometry'])\n",
        "    merged_lines = []\n",
        "    while lines:\n",
        "        current_line = lines.pop(0)\n",
        "        changed = True\n",
        "        while changed:\n",
        "            changed = False\n",
        "            for i, line in enumerate(lines):\n",
        "                if line.coords[0] == current_line.coords[-1]:\n",
        "                    current_line = LineString(list(current_line.coords) + list(line.coords[1:]))\n",
        "                    lines.pop(i)\n",
        "                    changed = True\n",
        "                    break\n",
        "                elif line.coords[-1] == current_line.coords[0]:\n",
        "                    current_line = LineString(list(line.coords[:-1]) + list(current_line.coords))\n",
        "                    lines.pop(i)\n",
        "                    changed = True\n",
        "                    break\n",
        "        merged_lines.append(current_line)\n",
        "    return merged_lines\n",
        "\n",
        "# Function to calculate the length-weighted mean\n",
        "def length_weighted_mean(group):\n",
        "    total_length = group['geometry'].length.sum()\n",
        "    if total_length == 0:\n",
        "        return 0\n",
        "    else:\n",
        "        return (group['value'] * group['geometry'].length).sum() / total_length\n",
        "\n",
        "def length_weighted_mean(group):\n",
        "    total_length = group['length'].sum()\n",
        "    if total_length == 0:\n",
        "        return 0\n",
        "    else:\n",
        "        return (group['value'] * group['length']).sum() / total_length\n"
      ],
      "id": "Import-necessary-library-and-all-defined-functionscalculate_tota",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: Download the road network for Area-of-Interest and read GeoJSON files\n",
        "\n",
        "gdf = gpd.read_file(\"data/rnet_princes_street.geojson\")\n",
        "gdf.shape"
      ],
      "id": "Download-the-road-network-for-Area-of-Interest-and-read-GeoJSON-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label:\n",
        "\n",
        "\n",
        "gdf_buffer = gdf.copy()\n",
        "gdf_buffer['geometry'] = gdf['geometry'].buffer(0.002)\n",
        "# Group the GeoDataFrame by 'value' and 'Quietness' columns\n",
        "grouped_gdf = gdf.groupby(['value', 'Quietness'])\n",
        "\n",
        "# Iterate through the groups and merge directly connected lines\n",
        "merged_lines_final = []\n",
        "for (value, quietness), group in grouped_gdf:\n",
        "    connected_lines = merge_directly_connected(group)\n",
        "    for line in connected_lines:\n",
        "        merged_lines_final.append({'value': value, 'Quietness': quietness, 'geometry': line})\n",
        "\n",
        "# Create a new GeoDataFrame with the merged and directly connected lines\n",
        "gdf_merged_directly_connected_final = gpd.GeoDataFrame(merged_lines_final, geometry='geometry')\n",
        "gdf_merged_directly_connected_final['length'] = gdf_merged_directly_connected_final['geometry'].length\n",
        "\n",
        "\n",
        "gdf = gdf_merged_directly_connected_final\n",
        "gdf_merged_directly_connected_final.to_file(\"data/gdf_merged_directly_connected_final.geojson\", driver='GeoJSON')\n",
        "gdf.shape\n",
        "\n",
        "# TODO: check total length after network simplification\n",
        "total_distance_traveled = round(sum(gdf['value'] * gdf['length']))\n",
        "total_distance_traveled\n",
        "\n",
        "\n",
        "# Applying the function to the GeoDataFrame\n",
        "segments_list_modified = []\n",
        "for index, row in gdf.iterrows():\n",
        "    segments = split_line_at_angles(row['geometry'], row['value'], row['Quietness'], index, row['length'], angle_threshold=30, max_length=0.01)\n",
        "    segments_list_modified.extend(segments)\n",
        "\n",
        "# Creating the new GeoDataFrame with the individual segments and additional attributes\n",
        "segments_gdf_modified = gpd.GeoDataFrame(segments_list_modified, columns=['geometry', 'value', 'Quietness', 'Ori_index', 'length'])\n",
        "\n",
        "# Displaying the first few rows of the result\n",
        "segments_gdf_modified.head()\n",
        "segments_gdf_modified.shape\n",
        "# Calculating the centroids of the geometries in segments_gdf_modified\n",
        "segments_gdf_modified_centroids = segments_gdf_modified.copy()\n",
        "segments_gdf_modified_centroids['geometry'] = segments_gdf_modified['geometry'].centroid\n",
        "\n",
        "segments_gdf_modified.to_file(\"data/segments_gdf_modified.geojson\", driver='GeoJSON')\n",
        "segments_gdf_modified_centroids.to_file(\"data/segments_gdf_modified_centroids.geojson\", driver='GeoJSON')\n",
        "\n",
        "\n",
        "# Read in simplified OS Road map data \n",
        "gdf_road_simplified = gpd.read_file(\"data/Edc_Roadlink.geojson\")\n",
        "gdf_road_simplified = gdf_road_simplified[['identifier', 'geometry']]\n",
        "gdf_road_simplified = gdf_road_simplified.to_crs(epsg=4326)\n",
        "\n",
        "# Plotting the geodataframes\n",
        "map = plot_geodataframes(('gdf', gdf), ('gdf_road_simplified', gdf_road_simplified),('segments_gdf_modified', segments_gdf_modified),('segments_gdf_modified_centroids', segments_gdf_modified_centroids),\n",
        "                          colors=['blue', 'red', 'green','black'], line_widths=(3.0, 2.0, 1.0,0.6), map_type=\"Esri Satellite\")\n",
        "map"
      ],
      "id": "ccba3405",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Requirement 1A: If multiple lines within the same buffer have the same 'Ori_index', it calculates the length-weighted mean of their 'value' attributes.\n",
        "Requirement 1B: If multiple lines within the same buffer have different 'Ori_index' values but the same 'Quietness', it calculates the length-weighted mean of their 'value' attributes.\n",
        "Requirement 2: If lines with the same 'Ori_index' are within different buffers, it calculates the length-weighted mean for the longer lines and adds that value to the corresponding buffer.\n"
      ],
      "id": "41bda3d5"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#Try to optimize the code by using spatial indexing techniques to reduce the number of geometry comparisons. To handle the large dataset more efficiently.\n",
        "gdf = segments_gdf_modified_centroids\n",
        "\n",
        "all_lines = gdf.index.tolist()\n",
        "\n",
        "# Step 1: Create a buffer around the geometries in gdf_road_simplified\n",
        "gdf_buffered = create_buffer(gdf_road_simplified, buffer_size=0.0001)\n",
        "\n",
        "# Performing a spatial join to find the lines within the buffer\n",
        "all_lines_within_buffer = gpd.sjoin(gdf, gdf_buffered, how=\"inner\", op=\"within\")\n",
        "\n",
        "gdf_buffered['value_sum'] = 0\n",
        "gdf_buffered['Line_index_from_gdf_Within'] = None\n",
        "all_lines_index_within_buffer = set()\n",
        "# gdf_buffered['length_sum'] = 0 \n",
        "\n",
        "# Iterating through the buffers\n",
        "for buffer_index, buffered_geom in gdf_buffered.iterrows():\n",
        "    # Filter lines within the current buffer\n",
        "    lines_within_buffer = all_lines_within_buffer[all_lines_within_buffer['index_right'] == buffer_index]\n",
        "    unprocessed_lines = lines_within_buffer.loc[~lines_within_buffer.index.isin(all_lines_index_within_buffer)]\n",
        "    gdf_buffered.at[buffer_index, 'Line_index_from_gdf_Within'] = unprocessed_lines.index.tolist()\n",
        "    all_lines_index_within_buffer.update(unprocessed_lines.index.tolist())\n",
        "    # gdf_buffered.at[buffer_index, 'length_sum'] = unprocessed_lines['length'].sum()\n",
        "\n",
        "    # Check if there are lines with the same 'Ori_index'\n",
        "    ori_indices_count = unprocessed_lines['Ori_index'].value_counts()\n",
        "    multiple_ori_indices = ori_indices_count[ori_indices_count > 1].index.tolist()\n",
        "\n",
        "    if multiple_ori_indices:\n",
        "        # Group by 'Ori_index' and calculate length-weighted mean for the lines with the same 'Ori_index'\n",
        "        for ori_index in multiple_ori_indices:\n",
        "            lines_group = unprocessed_lines[unprocessed_lines['Ori_index'] == ori_index]\n",
        "            length_weighted_mean_value = length_weighted_mean(lines_group)\n",
        "            gdf_buffered.at[buffer_index, 'value_sum'] += length_weighted_mean_value\n",
        "            # Remove the processed lines\n",
        "            unprocessed_lines = unprocessed_lines[unprocessed_lines['Ori_index'] != ori_index]\n",
        "\n",
        "    # Group by 'Quietness' and calculate length-weighted mean for the remaining lines\n",
        "    for quietness, lines_group in unprocessed_lines.groupby('Quietness'):\n",
        "        length_weighted_mean_value = length_weighted_mean(lines_group)\n",
        "        gdf_buffered.at[buffer_index, 'value_sum'] += length_weighted_mean_value\n",
        "        # Remove the processed lines\n",
        "        unprocessed_lines = unprocessed_lines[unprocessed_lines['Quietness'] != quietness]\n",
        "\n",
        "    # Add the remaining lines' 'value' to 'value_sum'\n",
        "    gdf_buffered.at[buffer_index, 'value_sum'] += unprocessed_lines['value'].sum()\n",
        "\n",
        "gdf_buffered.iloc[0]\n",
        "all_lines_within_buffer[all_lines_within_buffer['index_right'] == 0]\n",
        "\n",
        "# Define a custom aggregation function to retain the highest 'value_sum' value\n",
        "aggregation_functions = {'value_sum': 'max'}\n",
        "\n",
        "# Dissolve (combine) the lines with the same 'identifier' and apply the custom aggregation function\n",
        "gdf_buffered_dissolved = gdf_buffered.dissolve(by='identifier', aggfunc=aggregation_functions)\n",
        "\n",
        "gdf_buffered.shape\n",
        "gdf_buffered_dissolved.shape\n",
        "\n",
        "plot_buffer_with_lines(gdf_buffered, gdf, buffer_index=1477, relation='within')\n",
        "plot_buffer_with_lines(gdf_buffered, gdf, buffer_index=614, relation='within')\n",
        "gdf_buffered.iloc[1477]\n",
        "gdf_buffered.iloc[614]['Line_index_from_gdf_Within'] = [1175,1177]\n",
        "\n",
        "all_lines_within_buffer[all_lines_within_buffer['index_right'] == 1477]\n",
        "\n",
        "A = all_lines_within_buffer[all_lines_within_buffer['index_right'] == 614]['value']\n",
        "B = all_lines_within_buffer[all_lines_within_buffer['index_right'] == 614]['length']\n",
        "C = A *B\n",
        "C.sum()/B.sum()\n",
        "\n",
        "length_weighted_mean(all_lines_within_buffer[all_lines_within_buffer['index_right'] == 614].iloc[3:5])\n",
        "# # Create a list to store all lines intersecting any buffer\n",
        "# all_lines_index_intersect_buffer = []\n",
        "# gdf_buffered['Line_index_from_gdf_Intersect'] = None\n",
        "\n",
        "# # Spatial join between the buffers and the lines\n",
        "# joined_gdf = gpd.sjoin(gdf, gdf_buffered, how=\"inner\", op=\"intersects\")\n",
        "\n",
        "# # Iterate through the buffers\n",
        "# for buffer_index, buffered_geom in gdf_buffered.iterrows():\n",
        "#     indices_intersecting_buffer = []  # Indices of lines intersecting with the buffer\n",
        "#     value_sum = gdf_buffered.loc[buffer_index, 'value_sum']  # Existing value_sum for the buffer\n",
        "#     corresponding_road_line = gdf_road_simplified.loc[buffer_index]['geometry']  # Corresponding road line\n",
        "    \n",
        "#     # Filter lines intersecting the current buffer using the spatial join result\n",
        "#     lines_intersecting_buffer = joined_gdf[joined_gdf['index_right'] == buffer_index]\n",
        "\n",
        "#     for line_index, line_geom in lines_intersecting_buffer.iterrows():\n",
        "#         # Skip lines that are already within any buffer\n",
        "#         if line_index in all_lines_index_within_buffer:\n",
        "#             continue\n",
        "        \n",
        "#         vector1 = get_vector(line_geom['geometry'])\n",
        "#         vector2 = get_vector(corresponding_road_line)\n",
        "#         angle = calculate_angle(vector1, vector2)\n",
        "#         if angle < 25:\n",
        "#             value_sum += line_geom['value']\n",
        "#         indices_intersecting_buffer.append(line_index)\n",
        "\n",
        "#     gdf_buffered.at[buffer_index, 'value_sum'] = value_sum\n",
        "#     gdf_buffered.at[buffer_index, 'Line_index_from_gdf_Intersect'] = indices_intersecting_buffer\n",
        "#     all_lines_index_intersect_buffer.extend(indices_intersecting_buffer)\n",
        "\n",
        "\n",
        "# plot_buffer_with_lines(gdf_buffered, gdf, buffer_index=843, relation='intersect')    \n",
        "\n",
        "# missing_lines = set(all_lines) - set(all_lines_index_within_buffer) \n",
        "# -set(all_lines_index_intersect_buffer)\n",
        "# len(missing_lines)\n",
        "# Missed_gdf = gdf.loc[list(missing_lines)]\n",
        "\n",
        "# map = plot_geodataframes(('gdf', gdf), ('gdf_buffered', gdf_buffered),('Missed_gdf', Missed_gdf),\n",
        "                        #   colors=['blue', 'red', 'black'], line_widths=(3.0, 2.5, 5), map_type=\"Esri Satellite\")\n",
        "# map"
      ],
      "id": "8201749a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def find_examples():\n",
        "    # Dictionary to store examples\n",
        "    examples = {\"requirement_1\": [], \"requirement_2\": []}\n",
        "\n",
        "    # Iterate through buffers to find examples for Requirement 1\n",
        "    for buffer_index, buffer_row in gdf_buffered.iterrows():\n",
        "        lines_within_buffer = gdf.loc[buffer_row['Line_index_from_gdf_Within']]\n",
        "        grouped_by_ori_index = lines_within_buffer.groupby('Ori_index')\n",
        "        for ori_index, group in grouped_by_ori_index:\n",
        "            if len(group) > 1:\n",
        "                examples[\"requirement_1\"].append((buffer_index, ori_index, group))\n",
        "\n",
        "    # Iterate through unique 'Ori_index' values to find examples for Requirement 2\n",
        "    unique_ori_indexes = gdf['Ori_index'].unique()\n",
        "    for ori_index in unique_ori_indexes:\n",
        "        lines_with_same_ori_index = gdf[gdf['Ori_index'] == ori_index]\n",
        "        buffers_with_same_ori_index = gdf_buffered[gdf_buffered['Line_index_from_gdf_Within'].apply(lambda x: any(idx in x for idx in lines_with_same_ori_index.index))]\n",
        "        if len(buffers_with_same_ori_index) > 1:\n",
        "            examples[\"requirement_2\"].append((ori_index, buffers_with_same_ori_index))\n",
        "\n",
        "    return examples\n",
        "\n",
        "# Finding examples for the specific requirements\n",
        "examples = find_examples()\n",
        "\n",
        "# Displaying the first example for Requirement 1\n",
        "example_req1 = examples[\"requirement_1\"][0] if examples[\"requirement_1\"] else None\n",
        "example_req1_buffer_index, example_req1_ori_index, example_req1_group = example_req1 if example_req1 else (None, None, None)\n",
        "\n",
        "# Displaying the first example for Requirement 2\n",
        "example_req2 = examples[\"requirement_2\"][0] if examples[\"requirement_2\"] else None\n",
        "example_req2_ori_index, example_req2_buffers = example_req2 if example_req2 else (None, None)\n",
        "\n",
        "example_req1\n",
        "# plot_buffer_with_lines(gdf_buffered, gdf, buffer_index=405, relation='within')\n",
        "example_req2\n",
        "\n",
        "plot_buffer_with_lines(gdf_buffered, gdf, buffer_index=405, relation='within')\n",
        "\n",
        "# Examples\n",
        "plot_buffer_with_lines(gdf_buffered, gdf, buffer_index=1250, relation='within')\n",
        "gdf_buffered.iloc[614]['value_sum']\n",
        "plot_buffer_with_lines(gdf_buffered, gdf, buffer_index=1444, relation='within')\n",
        "plot_buffer_with_lines(gdf_buffered, gdf, buffer_index=1477, relation='within')\n",
        "gdf_buffered.iloc[463]['value_sum']\n",
        "\n",
        "\n",
        "# Extracting the details for the provided example\n",
        "example_buffer_index = 959\n",
        "example_line_index_gdf = 962\n",
        "example_line_index_road_simplified = 962\n",
        "\n",
        "# Getting the geometries for the example\n",
        "example_buffer_geom = gdf_buffered.loc[example_buffer_index]['geometry']\n",
        "example_line_gdf = gdf.loc[example_line_index_gdf]['geometry']\n",
        "example_line_road_simplified = gdf_road_simplified.loc[example_line_index_road_simplified]['geometry']\n",
        "\n",
        "# Calculating the vector and angle for the example\n",
        "vector_gdf = get_vector(example_line_gdf)\n",
        "vector_road_simplified = get_vector(example_line_road_simplified)\n",
        "example_angle = calculate_angle(vector_gdf, vector_road_simplified)\n",
        "\n",
        "# Checking the condition for adding the 'value'\n",
        "add_value_condition = example_angle < 25\n",
        "\n",
        "# Getting the 'value_sum' and 'Line_index_from_gdf_Intersect' for the corresponding buffer\n",
        "example_value_sum = gdf_buffered.loc[example_buffer_index]['value_sum']\n",
        "example_line_indices_intersect = gdf_buffered.loc[example_buffer_index]['Line_index_from_gdf_Intersect']\n",
        "\n",
        "example_angle, add_value_condition, example_value_sum, example_line_indices_intersect\n",
        "##############################################################"
      ],
      "id": "1d831c6b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Step 3: Match the attributes from gdf_buffered to gdf_road_simplified using the index, and then update gdf_road_simplified with these attributes.\n",
        "# Joining gdf_buffered with gdf_road_simplified on the index to combine attributes"
      ],
      "id": "e53cffb6"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Dissolve (combine) the lines with the same 'identifier'\n",
        "gdf_road_simplified = gdf_road_simplified.dissolve(by='identifier')\n",
        "gdf_road_simplified.shape\n",
        "\n",
        "gdf_road_simplified_updated = gdf_road_simplified.join(gdf_buffered[['value_sum']])\n",
        "# Displaying the first few rows of the updated gdf_road_simplified DataFrame\n",
        "gdf_road_simplified_updated.head()\n",
        "\n",
        "total_distance_traveled = round(sum(gdf_road_simplified_updated['value_sum'] * gdf_road_simplified_updated['geometry'].length))\n",
        "total_distance_traveled"
      ],
      "id": "bb5b9057",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "#| echo: false\n",
        "# Save gdf_road_simplified_updated as geojson\n",
        "gdf_to_save = gdf_road_simplified_updated[['value_sum', 'geometry']]\n",
        "gdf_to_save['v'] = gdf_to_save['value_sum'] / 500\n",
        "gdf_to_save.to_file(\"data/gdf_road_simplified_updated.geojson\", driver='GeoJSON')"
      ],
      "id": "361b367c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The code above generates output that has values from the detailed network merged onto the simplified network. \n",
        "The output is saved as a GeoJSON file.\n",
        "\n",
        "To recap, code below reads the input and output GeoJSON files and displays the first few rows of the output.\n"
      ],
      "id": "6ced43ef"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "input_detailed = gpd.read_file(\"data/rnet_princes_street.geojson\")\n",
        "input_simple = gpd.read_file(\"data/Edc_Roadlink.geojson\")\n",
        "input_detailed = input_detailed.to_crs('EPSG:27700')\n",
        "input_simple = input_simple.to_crs('EPSG:27700')\n",
        "# Union of input_simple:\n",
        "input_detailed_union = input_detailed['geometry'].unary_union\n",
        "# Buffer of 10 m around the union:\n",
        "input_detailed_buffer = input_detailed_union.buffer(30)\n",
        "# Convert to GeoDataFrame:\n",
        "input_detailed_buffer = gpd.GeoDataFrame([input_detailed_buffer])\n",
        "input_detailed_buffer.set_geometry(0, inplace=True)\n",
        "# Set CRS:\n",
        "input_detailed_buffer.crs = input_detailed.crs\n",
        "# the intersection of the simple network with the detailed buffered network:\n",
        "input_intersection = gpd.overlay(input_simple, input_detailed_buffer, how='intersection')\n",
        "# Plot both input and output networks with values represented by colour:\n",
        "# Todo: add colour/width to the lines\n",
        "# input_detailed.plot(line_width=input_detailed['value']/1000);\n",
        "# input_simple.plot(line_width=input_simple['value']/1000);\n",
        "input_detailed.plot(linewidth=input_detailed['value'] / 1000, cmap='Blues', legend=True);\n",
        "input_intersection.plot(linewidth=2);\n",
        "# input_intersection.to_file(\"data/Edc_Roadlink_simple.geojson\",driver='GeoJSON')"
      ],
      "id": "40f1e05b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The output is as follows:\n"
      ],
      "id": "713aef15"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "gdf_output = gpd.read_file(\"data/gdf_road_simplified_updated.geojson\")\n",
        "gdf_output.head()\n",
        "gdf_output[['value_sum']].mean()\n",
        "gdf_output_projected = gdf_output.to_crs('EPSG:27700')\n",
        "# calculate the length of each segment:\n",
        "gdf_output_projected['length'] = gdf_output_projected['geometry'].length\n",
        "gdf_output_projected.plot(linewidth=gdf_output_projected['value_sum'] / 1000, cmap='Blues', legend=True)\n"
      ],
      "id": "ce188686",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The total distance travelled on the input and output networks are as follows:\n"
      ],
      "id": "3dc7e8be"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "total_distance_traveled_input = round(sum(input_detailed['value'] * input_detailed['geometry'].length))\n",
        "round(total_distance_traveled_input / 1000)"
      ],
      "id": "bbb033c6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And on the output network:\n"
      ],
      "id": "9f13df88"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "total_distance_traveled_output = round(sum(gdf_output_projected['value_sum'] * gdf_output_projected['geometry'].length))\n",
        "round(total_distance_traveled_output / 1000)"
      ],
      "id": "d2572dfd",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}