{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "format: gfm\n",
        "---"
      ],
      "id": "5bd05c78"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Prerequisites\n",
        "\n",
        "To run the code in this repo, you need to have a working Python installation with the following packages installed (with pip in this case):\n",
        "\n",
        "\n",
        "```{bash}\n",
        "#| eval: false\n",
        "pip install matplotlib pandas shapely geopandas osmnx networkx scipy folium mapclassify\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "# Data Preparation and Processing\n",
        "\n",
        "The process is divided into several stages, each with a specific purpose, collectively contributing to the creation of a streamlined representation of the road network that emphasises essential cycling-related information. \n",
        "\n",
        "The process requires two main input datasets. The first is a GeoJSON file named \"rnet_princes_street.geojson,\" read into the system as input_detailed. This dataset represents the more intricate and detailed spatial information related to cycle commuting (stored in input_detailed['value']). The second is another GeoJSON file named \"Edc_Roadlink.geojson,\" read as input_simple, serving as the simplified road network onto which the detailed information will be projected.\n",
        "\n",
        "\n",
        "## 1. Preprocessing on input_detailed\n",
        "The preprocessing stage focuses on cleaning and restructuring the input_detailed data to set a unique index for each road. It involves merging spatially connected lines within the dataset, grouped by 'Value' and 'Quietness' attributes. A custom function, merge_directly_connected, is implemented for this purpose. The function uses a while loop that continuously joins lines if the start and end coordinates match, resulting in a set of merged lines. The purpose of this action is to eliminate redundancy and ensure that each road segment has a unique identifier, facilitating further analysis.\n",
        "\n",
        "## 2. Segmentation of input_detailed\n",
        "After preprocessing, the processed input_detailed data is then segmented using the split_line_at_angles function. This function computes the direction of each vector within a line and identifies indices where the angle between consecutive vectors exceeds a given threshold. The line is then split at these points into individual segments. The purpose of this action is to ensure that the following geospatial data analysis can produce more refined results by recognising and preserving significant changes in direction.\n",
        "\n",
        "Together, these stages transform the detailed spatial data into a format suitable for merging with the simplified road network. \n",
        "\n",
        "# Projecting cycle commuting data from input_detailed to input_simple\n",
        "The process of projecting cycle commuting data from the more detailed spatial information (input_detailed) to a simplified road network (input_simple) is carried out through a series of well-defined stages:\n",
        "\n",
        "## 1. Creating a Buffer around input_simple\n",
        "A new GeoDataFrame gdf_buffer is created around the geometries in input_simple using a predefined buffer size. This buffer serves as a zone within which lines from input_detailed will be analyzed and matched to the corresponding roads in input_simple.\n",
        "\n",
        "## 2.  Identifying Lines within the Buffer and Processing 'value' Attribute\n",
        "The first major step in this stage is to find the lines from input_detailed that fall within the buffer. The 'value' attribute associated with these lines is then processed according to three specific requirements:\n",
        "\n",
        "Requirement 1: If multiple lines with the same 'Ori_index' are within the same buffer, the mean 'value' of these lines is added to the buffer.\n",
        "\n",
        "Requirement 2: If lines with the same 'Ori_index' are within different buffers, the lengths of the lines are compared, and the 'value' is added to the buffer with the longer lines.\n",
        "\n",
        "Requirement 3: The 'value' of each line is added only once to ensure accuracy.\n",
        "\n",
        "In this section, instead of using standard geopandas functions like gpd.sjoin, the code implements a series of loops and dictionary structures. This custom approach meets the specific requirements, storing the index of lines within the buffer in gdf_buffered['Line_index_from_gdf_Within']  and ensuring that each 'value' is added only once.\n",
        "\n",
        "## 3. Identifying Lines that Intersect with the Buffer\n",
        "Lines from input_detailed that intersect with the buffer are also identified. This stage involves calculating the angle between intersecting lines and the corresponding lines in input_simple. The functions get_vector and calculate_angle are utilised to compute the vectors and angles, respectively.\n",
        "\n",
        "If the angle is less than 25 degrees, the intersecting lines are considered to be in the same direction as the corresponding line in input_simple, and their 'value' is added to the attribute gdf_buffered['value_sum']. The index of intersecting lines is recorded in gdf_buffered['Line_index_from_gdf_Intersect'].\n",
        "\n",
        "## 4. Final Data Aggregation\n",
        "In the final stage of the process, the attributes from gdf_buffered are matched to input_simple using the index. A join operation then updates input_simple with the attributes value_sum, effectively merging the processed cycle commuting data onto the simplified road network.\n"
      ],
      "id": "b309bb29"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: 'Import necessary library and all defined functions:calculate_total_length, plot_geodataframe_with_labels, plot_geodataframes, filter_data, create_buffer, get_vector, calculate_angle, split_line_at_angles, calculate_angle, filter_parallel_lines_concat, calculate_distance, plot_buffer_with_lines, merge_directly_connected'\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import math\n",
        "from typing import List, Tuple\n",
        "from shapely.geometry import LineString\n",
        "import geopandas as gpd\n",
        "import osmnx as ox\n",
        "import numpy as np\n",
        "from scipy.spatial.distance import pdist, squareform\n",
        "from shapely.geometry import Point, LineString, Polygon, MultiLineString\n",
        "import networkx as nx\n",
        "from pyproj import CRS\n",
        "import folium\n",
        "import os\n",
        "from numpy.linalg import norm\n",
        "from collections import defaultdict\n",
        "from shapely.ops import unary_union\n",
        "\n",
        "# Calculate total length of linestrings in a GeoDataFrame \n",
        "def calculate_total_length(gdf, crs=\"EPSG:4326\"):\n",
        "    # Copy the GeoDataFrame\n",
        "    gdf_projected = gdf.copy()\n",
        "\n",
        "    # Change the CRS to a UTM zone for more accurate length calculation\n",
        "    gdf_projected = gdf_projected.to_crs(crs)\n",
        "\n",
        "    # Calculate the length of each line\n",
        "    gdf_projected[\"length\"] = gdf_projected.length\n",
        "\n",
        "    # Calculate the total length\n",
        "    total_length = gdf_projected[\"length\"].sum()\n",
        "\n",
        "    return total_length\n",
        "\n",
        "# Plot GeoDataFrame and label each feature with its index\n",
        "def plot_geodataframe_with_labels(gdf, gdf_name):\n",
        "\n",
        "    # Create a new figure\n",
        "    fig, ax = plt.subplots(figsize=(10, 10))\n",
        "\n",
        "    # Plot the GeoDataFrame\n",
        "    gdf.plot(ax=ax)\n",
        "\n",
        "    # Add labels for each line with its index\n",
        "    for x, y, label in zip(gdf.geometry.centroid.x, gdf.geometry.centroid.y, gdf.index):\n",
        "        ax.text(x, y, str(label), fontsize=12)\n",
        "    plt.savefig(f\"pics/{gdf_name}.jpg\")\n",
        "    # Display the plot\n",
        "    plt.show()\n",
        "\n",
        "# Create interactive map from one or more GeoDataFrames  \n",
        "def plot_geodataframes(*args, colors=['red', 'blue', 'green'], line_widths=[3.5, 2.5,1.5], marker_sizes=[10, 10, 10], map_type=\"OpenStreetMap\"):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        *args: One or more (name, GeoDataFrame) tuples \n",
        "        colors: List of colors for lines\n",
        "        line_widths: List of line widths\n",
        "        map_type: Folium map type\n",
        "    Returns:\n",
        "        Folium map object\n",
        "    \"\"\"\n",
        "    # Prepare gdfs and their names\n",
        "    gdfs = [arg[1] for arg in args]\n",
        "    names = [arg[0] for arg in args]\n",
        "\n",
        "    # Initialize the map to the first point of the first geodataframe\n",
        "    start_point = gdfs[0].iloc[0].geometry.centroid.coords[0]\n",
        "    m = folium.Map(location=[start_point[1], start_point[0]], zoom_start=15)\n",
        "\n",
        "    if map_type == \"Esri Satellite\":\n",
        "        esri = folium.TileLayer(\n",
        "            tiles=\"https://server.arcgisonline.com/ArcGIS/rest/services/World_Imagery/MapServer/tile/{z}/{y}/{x}\",\n",
        "            attr=\"Esri\",\n",
        "            name=\"Esri Satellite\",\n",
        "            control=True\n",
        "        )\n",
        "        esri.add_to(m)\n",
        "\n",
        "    # Create feature groups for each geodataframe and add them to the map\n",
        "    for i, gdf in enumerate(gdfs):\n",
        "        fg = folium.FeatureGroup(name=names[i], show=False)\n",
        "        for _, row in gdf.iterrows():\n",
        "            if row.geometry.geom_type == 'Point':\n",
        "                marker = folium.Marker(location=[row.geometry.y, row.geometry.x], \n",
        "                                       icon=folium.Icon(color=colors[i % len(colors)]))\n",
        "                fg.add_child(marker)\n",
        "            elif row.geometry.geom_type == 'LineString':\n",
        "                line = folium.vector_layers.PolyLine(locations=[[p[1], p[0]] for p in list(row.geometry.coords)],\n",
        "                                                      color=colors[i % len(colors)],\n",
        "                                                      weight=line_widths[i % len(line_widths)])\n",
        "                fg.add_child(line)\n",
        "\n",
        "            elif row.geometry.geom_type == 'Polygon':\n",
        "                polygon = folium.vector_layers.Polygon(locations=[[p[1], p[0]] for p in list(row.geometry.exterior.coords)],\n",
        "                                                       color=colors[i % len(colors)],\n",
        "                                                       fill=True)\n",
        "                fg.add_child(polygon)\n",
        "            elif row.geometry.geom_type == 'MultiLineString':\n",
        "                for line_geom in row.geometry.geoms:\n",
        "                    coordinates = [list(p) for p in line_geom.coords]\n",
        "                    line = folium.vector_layers.PolyLine(locations=[[p[1], p[0]] for p in coordinates],\n",
        "                                                        color=colors[i % len(colors)],\n",
        "                                                        weight=line_widths[i % len(line_widths)])\n",
        "                    fg.add_child(line)                \n",
        "        m.add_child(fg)\n",
        "\n",
        "    # Add layer control to the map\n",
        "    folium.LayerControl().add_to(m)\n",
        "\n",
        "    return m\n",
        "\n",
        "# Filter GeoDataFrame based on column conditions  \n",
        "def filter_data(gdf, conditions):\n",
        "    \"\"\"\n",
        "    Filter a GeoDataFrame based on multiple conditions.\n",
        "\n",
        "    \"\"\"\n",
        "    for column, condition in conditions.items():\n",
        "        gdf = gdf[condition(gdf[column])]\n",
        "    return gdf\n",
        "\n",
        "# Buffer input geometries by specified distance\n",
        "def create_buffer(gdf, buffer_size = 0.00002):\n",
        "    gdf_buffered = gdf.copy()\n",
        "    gdf_buffered.geometry = gdf.geometry.buffer(buffer_size)\n",
        "    # gdf_buffered.to_file(\"data/gdf_buffered.geojson\", driver='GeoJSON')\n",
        "    return  gdf_buffered\n",
        "\n",
        "# Get start and end points from (Multi)LineString  \n",
        "def get_vector(line):\n",
        "    if isinstance(line, LineString):\n",
        "        start, end = line.coords[:2]\n",
        "    else:  # for MultiLineStrings, just use the first line\n",
        "        start, end = line.geoms[0].coords[:2]\n",
        "    return [end[0] - start[0], end[1] - start[1]]\n",
        "\n",
        "# Calculate angle between two vectors \n",
        "def calculate_angle(vector1, vector2):\n",
        "    dot_product = vector1[0] * vector2[0] + vector1[1] * vector2[1]\n",
        "    magnitude_product = math.sqrt(vector1[0]**2 + vector1[1]**2) * math.sqrt(vector2[0]**2 + vector2[1]**2)\n",
        "    cos_angle = dot_product / magnitude_product\n",
        "    angle = math.degrees(math.acos(cos_angle))\n",
        "    return angle\n",
        "\n",
        "# Modified function to split a line into segments based on an angle threshold and retain the 'value', 'Quietness', and original index\n",
        "def split_line_at_angles(line, value, quietness, original_index, threshold=30):\n",
        "    segments = []\n",
        "    if isinstance(line, LineString):\n",
        "        coords = np.array(line.coords)\n",
        "        # Compute the direction of each vector\n",
        "        vectors = np.diff(coords, axis=0)\n",
        "        directions = np.arctan2(vectors[:, 1], vectors[:, 0])\n",
        "        # Compute the angle between each pair of vectors\n",
        "        angles = np.diff(directions)\n",
        "        # Convert the angles to degrees and take absolute values\n",
        "        angles = np.abs(np.degrees(angles))\n",
        "        # Identify the indices where the angle exceeds the threshold\n",
        "        split_indices = np.where(angles > threshold)[0] + 1\n",
        "        # Split the line at the points corresponding to the split indices\n",
        "        last_index = 0\n",
        "        for index in split_indices:\n",
        "            segment = LineString(coords[last_index:index + 1])\n",
        "            segments.append((segment, value, quietness, original_index))\n",
        "            last_index = index\n",
        "        # Include all remaining parts of the line after the last split point\n",
        "        segment = LineString(coords[last_index:])\n",
        "        segments.append((segment, value, quietness, original_index))\n",
        "    elif isinstance(line, MultiLineString):\n",
        "        # Handle each LineString in the MultiLineString separately\n",
        "        for geom in line.geoms:\n",
        "            segments.extend(split_line_at_angles(geom, value, quietness, original_index, threshold))\n",
        "    else:\n",
        "        raise ValueError(f\"Unexpected geometry type: {type(line)}\")\n",
        "\n",
        "    return segments\n",
        "\n",
        "# Calculate angle between two line segments \n",
        "def calculate_angle(line1, line2):\n",
        "    # Define the vectors\n",
        "    vector1 = np.array(line1[1]) - np.array(line1[0])\n",
        "    vector2 = np.array(line2[1]) - np.array(line2[0])\n",
        "    \n",
        "    # Compute the dot product\n",
        "    dot_product = np.dot(vector1, vector2)\n",
        "    \n",
        "    # Compute the magnitudes of the vectors\n",
        "    magnitude1 = np.sqrt(np.dot(vector1, vector1))\n",
        "    magnitude2 = np.sqrt(np.dot(vector2, vector2))\n",
        "    \n",
        "    # Compute the angle between the vectors in radians\n",
        "    angle_rad = np.arccos(dot_product / (magnitude1 * magnitude2))\n",
        "    \n",
        "    # Convert the angle to degrees\n",
        "    angle_deg = np.degrees(angle_rad)\n",
        "    \n",
        "    return angle_deg\n",
        "\n",
        "# Concat parallel linestrings into single geometry\n",
        "def filter_parallel_lines_concat(gdf, name, angle_tolerance=25):\n",
        "    # Filter the GeoDataFrame by the 'name' column\n",
        "    filtered_gdf = gdf[gdf['name'] == name]\n",
        "\n",
        "    # Create a list to store the parallel lines\n",
        "    parallel_lines = []\n",
        "\n",
        "    # Iterate through each pair of lines\n",
        "    for i in range(len(filtered_gdf)):\n",
        "        for j in range(i+1, len(filtered_gdf)):\n",
        "            # Get the lines\n",
        "            line1 = list(filtered_gdf.iloc[i].geometry.coords)\n",
        "            line2 = list(filtered_gdf.iloc[j].geometry.coords)\n",
        "\n",
        "            # Calculate the angle between the lines\n",
        "            angle = calculate_angle(line1, line2)\n",
        "\n",
        "            # If the angle is close to 0 or 180 degrees, add the lines to the list\n",
        "            if abs(angle) <= angle_tolerance or abs(angle - 180) <= angle_tolerance:\n",
        "                parallel_lines.append(filtered_gdf.iloc[i:i+1])\n",
        "                parallel_lines.append(filtered_gdf.iloc[j:j+1])\n",
        "\n",
        "    # Combine the lines into a new GeoDataFrame using pd.concat\n",
        "    parallel_gdf = pd.concat(parallel_lines).drop_duplicates()\n",
        "\n",
        "    return parallel_gdf\n",
        "\n",
        "# Distance between two points\n",
        "def calculate_distance(point1, point2):\n",
        "    return Point(point1).distance(Point(point2))\n",
        "\n",
        "# Plot results of line within or intersect with buffer\n",
        "def plot_buffer_with_lines(gdf_buffered, gdf, buffer_index='all', relation='intersect'):\n",
        "    column_name = 'Line_index_from_gdf_Within' if relation == 'within' else 'Line_index_from_gdf_Intersect'\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(12, 8))\n",
        "\n",
        "    def plot_single_buffer(buffer_idx, buffered_geom):\n",
        "        indices_related_buffer = buffered_geom[column_name]\n",
        "        gpd.GeoSeries([buffered_geom['geometry']]).plot(ax=ax, edgecolor='blue', facecolor='none')\n",
        "\n",
        "        if indices_related_buffer:\n",
        "            gdf.loc[indices_related_buffer].plot(ax=ax, color='red')\n",
        "            for idx in indices_related_buffer:\n",
        "                line_value = gdf.loc[idx, 'value']\n",
        "                annotation_text = f\"{idx} - {line_value}\"\n",
        "                centroid = gdf.loc[idx, 'geometry'].centroid.coords[0]\n",
        "                plt.text(centroid[0], centroid[1] + 0.00005, annotation_text, fontsize=9, color='red', ha='center')\n",
        "        else:\n",
        "            plt.text(buffered_geom['geometry'].centroid.x, buffered_geom['geometry'].centroid.y - 0.00015, \"No lines \" + relation, fontsize=9, color='blue', ha='center')\n",
        "\n",
        "        plt.text(buffered_geom['geometry'].centroid.x, buffered_geom['geometry'].centroid.y - 0.00035, f\"Buffer Index: {buffer_idx}\", fontsize=9, color='blue', ha='center')\n",
        "\n",
        "    if buffer_index == 'all':\n",
        "        for buffer_idx, buffered_geom in gdf_buffered.iterrows():\n",
        "            plot_single_buffer(buffer_idx, buffered_geom)\n",
        "        plt.title(f'Buffered Geometries (Blue) with {relation.capitalize()} Lines (Red)')\n",
        "    elif isinstance(buffer_index, int):\n",
        "        plot_single_buffer(buffer_index, gdf_buffered.loc[buffer_index])\n",
        "        plt.title(f'Buffered Geometry (Blue) with {relation.capitalize()} Lines (Red) for Buffer Index {buffer_index}')\n",
        "\n",
        "    plt.xlabel('Longitude')\n",
        "    plt.ylabel('Latitude')\n",
        "    plt.show()\n",
        "\n",
        "# Function to merge directly connected line segments within a group\n",
        "def merge_directly_connected(group):\n",
        "    lines = list(group['geometry'])\n",
        "    merged_lines = []\n",
        "    while lines:\n",
        "        current_line = lines.pop(0)\n",
        "        changed = True\n",
        "        while changed:\n",
        "            changed = False\n",
        "            for i, line in enumerate(lines):\n",
        "                if line.coords[0] == current_line.coords[-1]:\n",
        "                    current_line = LineString(list(current_line.coords) + list(line.coords[1:]))\n",
        "                    lines.pop(i)\n",
        "                    changed = True\n",
        "                    break\n",
        "                elif line.coords[-1] == current_line.coords[0]:\n",
        "                    current_line = LineString(list(line.coords[:-1]) + list(current_line.coords))\n",
        "                    lines.pop(i)\n",
        "                    changed = True\n",
        "                    break\n",
        "        merged_lines.append(current_line)\n",
        "    return merged_lines"
      ],
      "id": "Import-necessary-library-and-all-defined-functionscalculate_tota",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: Download the road network for Area-of-Interest and read GeoJSON files\n",
        "\n",
        "# # Define the centre point of AoT from OSM\n",
        "# point = (55.952227 , -3.1959271)\n",
        "# distance = 1300  # in meters\n",
        "\n",
        "# # Only download if the data/edges.shp file does not exist:\n",
        "# if not os.path.exists(\"data/edges.shp\"):\n",
        "#     # Download the road network data\n",
        "#     graph = ox.graph_from_point(point, dist=distance, network_type='all')\n",
        "\n",
        "#     # Save the road network as a shapefile\n",
        "#     ox.save_graph_shapefile(graph, filepath=r'data/')\n",
        "\n",
        "# Read in data from CycleStreets \n",
        "gdf = gpd.read_file(\"data/rnet_princes_street.geojson\")\n",
        "gdf = gdf.rename(columns={'commute_fastest_bicycle_go_dutch': 'value'})\n",
        "\n",
        "# Group the GeoDataFrame by 'value' and 'Quietness' columns\n",
        "grouped_gdf = gdf.groupby(['value', 'Quietness'])\n",
        "\n",
        "# Iterate through the groups and merge directly connected lines\n",
        "merged_lines_final = []\n",
        "for (value, quietness), group in grouped_gdf:\n",
        "    connected_lines = merge_directly_connected(group)\n",
        "    for line in connected_lines:\n",
        "        merged_lines_final.append({'value': value, 'Quietness': quietness, 'geometry': line})\n",
        "\n",
        "# Create a new GeoDataFrame with the merged and directly connected lines\n",
        "gdf_merged_directly_connected_final = gpd.GeoDataFrame(merged_lines_final, geometry='geometry')\n",
        "gdf_merged_directly_connected_final['length'] = gdf_merged_directly_connected_final['geometry'].length\n",
        "\n",
        "# gdf_merged_directly_connected_final.to_file(\"data/gdf_merged_directly_connected_final.geojson\", driver='GeoJSON')\n",
        "\n",
        "gdf = gdf_merged_directly_connected_final\n",
        "\n",
        "\n",
        "# TODO: check total length after network simplification\n",
        "total_distance_traveled = round(sum(gdf['value'] * gdf['length']))\n",
        "total_distance_traveled\n",
        "\n",
        "\n",
        "# Applying the split function to the gdf GeoDataFrame\n",
        "segments_list_modified = []\n",
        "for index, row in gdf.iterrows():\n",
        "    segments = split_line_at_angles(row['geometry'], row['value'], row['Quietness'], index)\n",
        "    segments_list_modified.extend(segments)\n",
        "\n",
        "# Creating a new GeoDataFrame with the individual segments and additional attributes\n",
        "segments_gdf_modified = gpd.GeoDataFrame(segments_list_modified, columns=['geometry', 'value', 'Quietness', 'Ori_index'])\n",
        "segments_gdf_modified['value'].sum(), segments_gdf_modified.shape, segments_gdf_modified.head()\n",
        "segments_gdf_modified.shape\n",
        "segments_gdf_modified.to_file(\"data/segments_gdf_modified.geojson\", driver='GeoJSON')\n",
        "\n",
        "# # Filter the data with conditions\n",
        "# conditions = {\n",
        "#     'value': lambda x: x != 0\n",
        "# }\n",
        "\n",
        "# filtered_gdf = filter_data(gdf, conditions)\n",
        "\n",
        "# Read in simplified OS Road map data \n",
        "gdf_road_simplified = gpd.read_file(\"data/Edc_Roadlink.geojson\")\n",
        "gdf_road_simplified = gdf_road_simplified[['identifier', 'geometry']]\n",
        "gdf_road_simplified.crs = \"EPSG:4326\"\n",
        "\n",
        "\n",
        "# Plotting the geodataframes\n",
        "map = plot_geodataframes(('gdf', gdf), ('gdf_road_simplified', gdf_road_simplified),('segments_gdf_modified', segments_gdf_modified),('gdf_merged_directly_connected_final', gdf_merged_directly_connected_final),\n",
        "                          colors=['blue', 'red', 'green','black'], line_widths=(3.0, 2.0, 1.0,0.6), map_type=\"Esri Satellite\")\n",
        "# map"
      ],
      "id": "Download-the-road-network-for-Area-of-Interest-and-read-GeoJSON-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: Join attribute (commute_fastest_bicycle_go_dutch) from gdf to gdf_road_simplified\n",
        "#| eval: false\n",
        "gdf = segments_gdf_modified\n",
        "all_lines = gdf.index.tolist()\n",
        "\n",
        "# Step 1: Create a buffer around the geometries in gdf_road_simplified\n",
        "gdf_buffered = create_buffer(gdf_road_simplified, buffer_size=0.00022)\n",
        "\n",
        "# Step 2.1: identifying all lines in gdf that are within the buffer\n",
        "# Initializing the required columns\n",
        "\n",
        "gdf_buffered['value_sum'] = 0\n",
        "gdf_buffered['Line_index_from_gdf_Within'] = None\n",
        "all_lines_within_buffer = []\n",
        "\n",
        "# Dictionary to store lines across different buffers grouped by 'Ori_index'\n",
        "# Iterate through the buffered geometries to find lines within the buffer and sum their 'value'\n",
        "\n",
        "lines_across_buffers_by_ori_index = defaultdict(list)\n",
        "\n",
        "for buffer_index, buffered_geom in gdf_buffered.iterrows():\n",
        "    # Dictionary to store lines grouped by 'Ori_index' within the current buffer\n",
        "    lines_within_buffer_by_ori_index = defaultdict(list)\n",
        "\n",
        "    # Find lines within the buffer and group them by 'Ori_index'\n",
        "    indices_within_buffer = []\n",
        "    for line_index, line_geom in gdf.iterrows():\n",
        "        if line_geom['geometry'].within(buffered_geom['geometry']):\n",
        "            lines_within_buffer_by_ori_index[line_geom['Ori_index']].append((line_index, line_geom['value'], line_geom['geometry'].length))\n",
        "            indices_within_buffer.append(line_index)\n",
        "\n",
        "    # Store the lines grouped by 'Ori_index' for comparison across buffers\n",
        "    for ori_index, lines in lines_within_buffer_by_ori_index.items():\n",
        "        lines_across_buffers_by_ori_index[ori_index].append((buffer_index, lines))\n",
        "\n",
        "    # Placeholder for value sum; actual sum will be calculated later\n",
        "    gdf_buffered.at[buffer_index, 'Line_index_from_gdf_Within'] = indices_within_buffer\n",
        "    all_lines_within_buffer.extend(indices_within_buffer)\n",
        "\n",
        "# Set to keep track of processed lines\n",
        "processed_lines = set()\n",
        "\n",
        "# Iterate through lines grouped by 'Ori_index' across buffers\n",
        "for ori_index, buffers_with_lines in lines_across_buffers_by_ori_index.items():\n",
        "    if len(buffers_with_lines) == 1:\n",
        "        # Requirement 1: All lines with the same 'Ori_index' are within the same buffer\n",
        "        buffer_index, lines = buffers_with_lines[0]\n",
        "        mean_value = sum(line[1] for line in lines if line[0] not in processed_lines) / len(lines)\n",
        "        gdf_buffered.at[buffer_index, 'value_sum'] += mean_value\n",
        "        processed_lines.update(line[0] for line in lines)\n",
        "    else:\n",
        "        # Requirement 2: Lines with the same 'Ori_index' are within different buffers\n",
        "        max_length_buffer = max(buffers_with_lines, key=lambda x: sum(line[2] for line in x[1] if line[0] not in processed_lines))\n",
        "        mean_value = sum(line[1] for line in max_length_buffer[1] if line[0] not in processed_lines) / len(max_length_buffer[1])\n",
        "        gdf_buffered.at[max_length_buffer[0], 'value_sum'] += mean_value\n",
        "        processed_lines.update(line[0] for line in max_length_buffer[1])\n",
        "\n",
        "\n",
        "plot_buffer_with_lines(gdf_buffered, gdf, buffer_index=1477, relation='within')\n",
        "\n",
        "\n",
        "# Helper function to find examples that meet Requirement 1 and Requirement 2\n",
        "# Requirement 1: If there are multiple lines with the same 'Ori_index' value within the same buffer, the mean value of those lines should be added to the buffer.\n",
        "# Requirement 2: If there are lines with the same 'Ori_index' value but within different buffers, compare the lengths of the lines. If the length of lines with the same 'Ori_index' in one buffer is shorter than the lines in another buffer, only add the value of the lines in the buffer with the longer lines.\n",
        "\n",
        "def find_examples():\n",
        "    # Dictionary to store examples\n",
        "    examples = {\"requirement_1\": [], \"requirement_2\": []}\n",
        "\n",
        "    # Iterate through buffers to find examples for Requirement 1\n",
        "    for buffer_index, buffer_row in gdf_buffered.iterrows():\n",
        "        lines_within_buffer = gdf.loc[buffer_row['Line_index_from_gdf_Within']]\n",
        "        grouped_by_ori_index = lines_within_buffer.groupby('Ori_index')\n",
        "        for ori_index, group in grouped_by_ori_index:\n",
        "            if len(group) > 1:\n",
        "                examples[\"requirement_1\"].append((buffer_index, ori_index, group))\n",
        "\n",
        "    # Iterate through unique 'Ori_index' values to find examples for Requirement 2\n",
        "    unique_ori_indexes = gdf['Ori_index'].unique()\n",
        "    for ori_index in unique_ori_indexes:\n",
        "        lines_with_same_ori_index = gdf[gdf['Ori_index'] == ori_index]\n",
        "        buffers_with_same_ori_index = gdf_buffered[gdf_buffered['Line_index_from_gdf_Within'].apply(lambda x: any(idx in x for idx in lines_with_same_ori_index.index))]\n",
        "        if len(buffers_with_same_ori_index) > 1:\n",
        "            examples[\"requirement_2\"].append((ori_index, buffers_with_same_ori_index))\n",
        "\n",
        "    return examples\n",
        "\n",
        "# Finding examples for the specific requirements\n",
        "examples = find_examples()\n",
        "\n",
        "# Displaying the first example for Requirement 1\n",
        "example_req1 = examples[\"requirement_1\"][0] if examples[\"requirement_1\"] else None\n",
        "example_req1_buffer_index, example_req1_ori_index, example_req1_group = example_req1 if example_req1 else (None, None, None)\n",
        "\n",
        "# Displaying the first example for Requirement 2\n",
        "example_req2 = examples[\"requirement_2\"][0] if examples[\"requirement_2\"] else None\n",
        "example_req2_ori_index, example_req2_buffers = example_req2 if example_req2 else (None, None)\n",
        "\n",
        "example_req1\n",
        "# plot_buffer_with_lines(gdf_buffered, gdf, buffer_index=405, relation='within')\n",
        "example_req2\n",
        "\n",
        "plot_buffer_with_lines(gdf_buffered, gdf, buffer_index=405, relation='within')\n",
        "\n",
        "# Examples\n",
        "plot_buffer_with_lines(gdf_buffered, gdf, buffer_index=614, relation='within')\n",
        "gdf_buffered.iloc[614]['value_sum']\n",
        "plot_buffer_with_lines(gdf_buffered, gdf, buffer_index=463, relation='within')\n",
        "plot_buffer_with_lines(gdf_buffered, gdf, buffer_index=1476, relation='within')\n",
        "gdf_buffered.iloc[463]['value_sum']\n",
        "\n",
        "##############################################################\n",
        "# Step 2.2: identifying all lines in gdf that intersect with the buffer\n",
        "all_lines_intersect_buffer = []\n",
        "gdf_buffered['Line_index_from_gdf_Intersect'] = None\n",
        "for buffer_index, buffered_geom in gdf_buffered.iterrows():\n",
        "    indices_intersecting_buffer = []  # Indices of lines intersecting with the buffer\n",
        "    value_sum = gdf_buffered.loc[buffer_index, 'value_sum']  # Existing value_sum for the buffer\n",
        "    corresponding_road_line = gdf_road_simplified.loc[buffer_index]['geometry']  # Corresponding road line\n",
        "    for line_index, line_geom in gdf.iterrows():\n",
        "        # Skip lines that are already within any buffer\n",
        "        if line_index in all_lines_within_buffer:\n",
        "            continue\n",
        "        if line_geom['geometry'].intersects(buffered_geom['geometry']):\n",
        "            vector1 = get_vector(line_geom['geometry'])\n",
        "            vector2 = get_vector(corresponding_road_line)\n",
        "            angle = calculate_angle(vector1, vector2)\n",
        "            if angle < 25:\n",
        "                value_sum += line_geom['value']\n",
        "            indices_intersecting_buffer.append(line_index)\n",
        "    gdf_buffered.at[buffer_index, 'value_sum'] = value_sum\n",
        "    gdf_buffered.at[buffer_index, 'Line_index_from_gdf_Intersect'] = indices_intersecting_buffer\n",
        "    all_lines_intersect_buffer.extend(indices_intersecting_buffer)\n",
        "\n",
        "plot_buffer_with_lines(gdf_buffered, gdf, buffer_index=614, relation='intersect')\n",
        "\n",
        "gdf_buffered.iloc[1477]['value_sum']\n",
        "\n",
        "# Finding the missed lines using buffer methods\n",
        "missing_lines = set(all_lines) - set(all_lines_within_buffer) - set(all_lines_intersect_buffer)\n",
        "len(missing_lines)\n",
        "Missed_gdf = gdf.loc[list(missing_lines)]\n",
        "\n",
        "map = plot_geodataframes(('gdf', gdf), ('gdf_buffered', gdf_buffered),('Missed_gdf', Missed_gdf),\n",
        "                          colors=['blue', 'red', 'black'], line_widths=(3.0, 2.5, 5), map_type=\"Esri Satellite\")\n",
        "map\n",
        "\n",
        "##############################################################\n",
        "\n",
        "# Extracting the details for the provided example\n",
        "example_buffer_index = 959\n",
        "example_line_index_gdf = 962\n",
        "example_line_index_road_simplified = 962\n",
        "\n",
        "# Getting the geometries for the example\n",
        "example_buffer_geom = gdf_buffered.loc[example_buffer_index]['geometry']\n",
        "example_line_gdf = gdf.loc[example_line_index_gdf]['geometry']\n",
        "example_line_road_simplified = gdf_road_simplified.loc[example_line_index_road_simplified]['geometry']\n",
        "\n",
        "# Calculating the vector and angle for the example\n",
        "vector_gdf = get_vector(example_line_gdf)\n",
        "vector_road_simplified = get_vector(example_line_road_simplified)\n",
        "example_angle = calculate_angle(vector_gdf, vector_road_simplified)\n",
        "\n",
        "# Checking the condition for adding the 'value'\n",
        "add_value_condition = example_angle < 25\n",
        "\n",
        "# Getting the 'value_sum' and 'Line_index_from_gdf_Intersect' for the corresponding buffer\n",
        "example_value_sum = gdf_buffered.loc[example_buffer_index]['value_sum']\n",
        "example_line_indices_intersect = gdf_buffered.loc[example_buffer_index]['Line_index_from_gdf_Intersect']\n",
        "\n",
        "example_angle, add_value_condition, example_value_sum, example_line_indices_intersect\n",
        "##############################################################\n",
        "\n",
        "# Step 3: Match the attributes from gdf_buffered to gdf_road_simplified using the index, and then update gdf_road_simplified with these attributes.\n",
        "# Joining gdf_buffered with gdf_road_simplified on the index to combine attributes\n",
        "gdf_road_simplified_updated = gdf_road_simplified.join(gdf_buffered[['value_sum', 'Line_index_from_gdf_Within', 'Line_index_from_gdf_Intersect']])\n",
        "\n",
        "# Displaying the first few rows of the updated gdf_road_simplified DataFrame\n",
        "gdf_road_simplified_updated.head()\n",
        "\n",
        "total_distance_traveled = round(sum(gdf_road_simplified_updated['value_sum'] * gdf_road_simplified_updated['geometry'].length))\n",
        "total_distance_traveled"
      ],
      "id": "Join-attribute-commute_fastest_bicycle_go_dutch-from-gdf-to-gdf_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "#| echo: false\n",
        "# Save gdf_road_simplified_updated as geojson\n",
        "gdf_to_save = gdf_road_simplified_updated[['value_sum', 'geometry']]\n",
        "gdf_to_save.to_file(\"data/gdf_road_simplified_updated.geojson\", driver='GeoJSON')"
      ],
      "id": "8f543348",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The code above generates output that has values from the detailed network merged onto the simplified network. \n",
        "The output is saved as a GeoJSON file.\n",
        "\n",
        "To recap, code below reads the input and output GeoJSON files and displays the first few rows of the output.\n"
      ],
      "id": "4f7e3d03"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "input_detailed = gpd.read_file(\"data/rnet_princes_street.geojson\")\n",
        "input_simple = gpd.read_file(\"data/Edc_Roadlink.geojson\")\n",
        "input_detailed = input_detailed.to_crs('EPSG:27700')\n",
        "input_simple = input_simple.to_crs('EPSG:27700')\n",
        "# Union of input_simple:\n",
        "input_detailed_union = input_detailed['geometry'].unary_union\n",
        "# Buffer of 10 m around the union:\n",
        "input_detailed_buffer = input_detailed_union.buffer(30)\n",
        "# Convert to GeoDataFrame:\n",
        "input_detailed_buffer = gpd.GeoDataFrame([input_detailed_buffer])\n",
        "input_detailed_buffer.set_geometry(0, inplace=True)\n",
        "# Set CRS:\n",
        "input_detailed_buffer.crs = input_detailed.crs\n",
        "# the intersection of the simple network with the detailed buffered network:\n",
        "input_intersection = gpd.overlay(input_simple, input_detailed_buffer, how='intersection')\n",
        "# Plot both input and output networks with values represented by colour:\n",
        "input_detailed.plot(linewidth=input_detailed['commute_fastest_bicycle_go_dutch']/1000, cmap='Blues', legend=True);\n",
        "input_intersection.plot(color='red', linewidth=2);"
      ],
      "id": "8966aaff",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The output is as follows:\n"
      ],
      "id": "1a56034b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "gdf_output = gpd.read_file(\"data/gdf_road_simplified_updated.geojson\")\n",
        "gdf_output.head()\n",
        "gdf_output[['value_sum']].mean()\n",
        "gdf_output_projected = gdf_output.to_crs('EPSG:27700')\n",
        "# calculate the length of each segment:\n",
        "gdf_output_projected['length'] = gdf_output_projected['geometry'].length"
      ],
      "id": "bd48d8cf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The total distance travelled on the input and output networks are as follows:\n"
      ],
      "id": "48adc6cc"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "total_distance_traveled_input = round(sum(input_detailed['commute_fastest_bicycle_go_dutch'] * input_detailed['geometry'].length))\n",
        "round(total_distance_traveled_input / 1000)"
      ],
      "id": "fd56691b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And on the output network:\n"
      ],
      "id": "1b79bded"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "total_distance_traveled_output = round(sum(gdf_output_projected['value_sum'] * gdf_output_projected['geometry'].length))\n",
        "round(total_distance_traveled_output / 1000)"
      ],
      "id": "dc0c1f8e",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}